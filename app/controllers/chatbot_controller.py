from fastapi import APIRouter, HTTPException, Depends, Query
from typing import Dict, Any, Optional, List
import logging
import os
from datetime import datetime

from app.models.chatbot_data import ChatbotDataResponse, ChatbotQuery, ChatMessage, ChatResponse
from app.services.chatbot_service import ChatbotService
from app.services.gemini_service import GeminiChatService
from app.config.settings import settings

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/chatbot", tags=["chatbot"])

# Dependency para obtener el servicio del chatbot
def get_chatbot_service() -> ChatbotService:
    """Dependency para inyectar el servicio del chatbot"""
    return ChatbotService(settings.csv_file_path)

# Cache global para mantener el contexto del chat
_gemini_service_cache = {}

def get_gemini_service() -> GeminiChatService:
    """Dependency para inyectar el servicio de Gemini con contexto persistente"""
    # Usar un ID de sesi√≥n simple (en producci√≥n usar√≠as session ID real)
    session_id = "default_session"
    
    if session_id not in _gemini_service_cache:
        gemini_api_key = settings.gemini_api_key or os.getenv('GEMINI_API_KEY')
        csv_path = settings.csv_file_path
        _gemini_service_cache[session_id] = GeminiChatService(gemini_api_key, csv_path)
    
    return _gemini_service_cache[session_id]

@router.get("/data", response_model=ChatbotDataResponse)
async def get_complete_data_for_chatbot(
    chatbot_service: ChatbotService = Depends(get_chatbot_service)
):
    """
    Endpoint principal para el chatbot - Retorna TODA la informaci√≥n del sistema
    
    Este endpoint est√° dise√±ado para ser consumido por un chatbot/LLM y contiene:
    - Resumen completo de todas las estaciones
    - Informaci√≥n detallada de todas las variables
    - Estad√≠sticas globales y por estaci√≥n
    - Cobertura temporal y geogr√°fica
    - Informaci√≥n de calidad de datos
    - Contexto para el chatbot
    
    Ideal para sistemas RAG (Retrieval-Augmented Generation)
    """
    try:
        logger.info("Generando datos completos para chatbot")
        complete_data = chatbot_service.get_complete_data_for_chatbot()
        logger.info(f"Datos generados: {len(complete_data.stations)} estaciones, {len(complete_data.variables)} variables")
        return complete_data
    except Exception as e:
        logger.error(f"Error generando datos para chatbot: {e}")
        raise HTTPException(status_code=500, detail="Error interno del servidor")

@router.post("/query")
async def query_filtered_data(
    query: ChatbotQuery,
    chatbot_service: ChatbotService = Depends(get_chatbot_service)
):
    """
    Endpoint para consultas espec√≠ficas del chatbot
    
    Permite al chatbot hacer consultas filtradas por:
    - Estaciones espec√≠ficas
    - Variables espec√≠ficas  
    - Rangos de fechas
    - Incluir o no datos crudos
    - Limitar n√∫mero de registros
    """
    try:
        logger.info(f"Procesando query del chatbot: {query.dict()}")
        filtered_data = chatbot_service.get_filtered_data(query)
        return filtered_data
    except Exception as e:
        logger.error(f"Error procesando query del chatbot: {e}")
        raise HTTPException(status_code=500, detail="Error procesando consulta")

@router.get("/stations/summary")
async def get_stations_summary_for_chatbot(
    station_ids: Optional[List[int]] = Query(None, description="IDs espec√≠ficos de estaciones"),
    chatbot_service: ChatbotService = Depends(get_chatbot_service)
):
    """
    Resumen r√°pido de estaciones para el chatbot
    
    √ötil cuando el chatbot necesita informaci√≥n espec√≠fica de ciertas estaciones
    sin cargar todo el dataset completo.
    """
    try:
        complete_data = chatbot_service.get_complete_data_for_chatbot()
        
        if station_ids:
            filtered_stations = [
                station for station in complete_data.stations 
                if station.station_id in station_ids
            ]
            return {"stations": filtered_stations}
        
        return {"stations": complete_data.stations}
    except Exception as e:
        logger.error(f"Error obteniendo resumen de estaciones: {e}")
        raise HTTPException(status_code=500, detail="Error interno del servidor")

@router.get("/variables/info")
async def get_variables_info_for_chatbot(
    variables: Optional[List[str]] = Query(None, description="Variables espec√≠ficas"),
    chatbot_service: ChatbotService = Depends(get_chatbot_service)
):
    """
    Informaci√≥n detallada de variables para el chatbot
    
    Proporciona al chatbot informaci√≥n t√©cnica sobre las variables disponibles,
    incluyendo unidades, rangos v√°lidos, y estad√≠sticas de calidad.
    """
    try:
        complete_data = chatbot_service.get_complete_data_for_chatbot()
        
        if variables:
            filtered_variables = [
                var for var in complete_data.variables 
                if var.name in variables
            ]
            return {"variables": filtered_variables}
        
        return {"variables": complete_data.variables}
    except Exception as e:
        logger.error(f"Error obteniendo informaci√≥n de variables: {e}")
        raise HTTPException(status_code=500, detail="Error interno del servidor")

@router.get("/context")
async def get_context_for_chatbot(
    chatbot_service: ChatbotService = Depends(get_chatbot_service)
):
    """
    Informaci√≥n contextual para el chatbot
    
    Proporciona contexto sobre el sistema, prop√≥sito, alcance temporal y geogr√°fico.
    √ötil para que el chatbot entienda de qu√© trata el sistema y pueda dar respuestas
    m√°s informadas.
    """
    try:
        complete_data = chatbot_service.get_complete_data_for_chatbot()
        
        return {
            "system_info": complete_data.system_info,
            "context_info": complete_data.context_info,
            "global_stats": complete_data.global_stats,
            "temporal_coverage": complete_data.temporal_coverage,
            "geographic_coverage": complete_data.geographic_coverage
        }
    except Exception as e:
        logger.error(f"Error obteniendo contexto para chatbot: {e}")
        raise HTTPException(status_code=500, detail="Error interno del servidor")

@router.get("/health")
async def chatbot_service_health(
    chatbot_service: ChatbotService = Depends(get_chatbot_service)
):
    """
    Health check del servicio del chatbot
    
    Verifica que el servicio est√© funcionando correctamente y proporciona
    informaci√≥n b√°sica sobre el estado de los datos.
    """
    try:
        # Verificar que los datos se pueden cargar
        complete_data = chatbot_service.get_complete_data_for_chatbot()
        
        return {
            "status": "healthy",
            "data_loaded": True,
            "total_stations": len(complete_data.stations),
            "total_variables": len(complete_data.variables),
            "last_check": complete_data.system_info["last_updated"],
            "service_ready": True
        }
    except Exception as e:
        logger.error(f"Health check fall√≥: {e}")
        return {
            "status": "unhealthy",
            "data_loaded": False,
            "error": str(e),
            "service_ready": False
        }

# ==========================================
# ENDPOINTS DE CHAT CONVERSACIONAL CON GEMINI
# ==========================================

@router.post("/message", response_model=ChatResponse)
async def send_chat_message(
    message: ChatMessage,
    chatbot_service: ChatbotService = Depends(get_chatbot_service)
):
    """
    Endpoint principal para el chat conversacional con Nubi ‚òÅÔ∏è
    
    Sistema h√≠brido que combina:
    1. Respuestas heur√≠sticas r√°pidas para preguntas comunes
    2. IA (Gemini) para preguntas complejas sobre clima
    3. Validaci√≥n de scope y fallbacks inteligentes
    
    Este endpoint maneja:
    - Preguntas b√°sicas con respuestas instant√°neas
    - An√°lisis inteligente de datos meteorol√≥gicos
    - Explicaciones de conceptos clim√°ticos
    - Informaci√≥n de estaciones espec√≠ficas
    """
    try:
        logger.info(f"Procesando mensaje con sistema h√≠brido: {message.message}")
        
        # Usar el nuevo sistema h√≠brido
        response_text = await chatbot_service.responder_pregunta(message.message)
        
        timestamp = datetime.now().isoformat()
        
        return ChatResponse(
            response=response_text,
            timestamp=timestamp,
            status="success"
        )
        
    except Exception as e:
        logger.error(f"Error procesando mensaje: {e}")
        raise HTTPException(
            status_code=500, 
            detail="Error procesando el mensaje del chat"
        )

@router.get("/chat/health")
async def chat_health(
    chatbot_service: ChatbotService = Depends(get_chatbot_service)
):
    """
    Health check para el sistema h√≠brido de chat
    
    Verifica:
    - Estado del sistema heur√≠stico (siempre disponible)
    - Disponibilidad de Gemini IA
    - Conectividad con los datos meteorol√≥gicos
    - Capacidades del sistema h√≠brido
    """
    try:
        # Verificar datos b√°sicos
        data_available = chatbot_service.df is not None and len(chatbot_service.df) > 0
        
        # Verificar Gemini
        gemini_available = chatbot_service.has_gemini
        
        # Determinar estado general
        if data_available and gemini_available:
            status = "healthy"
            message = "Sistema h√≠brido completamente funcional"
        elif data_available:
            status = "degraded" 
            message = "Funcionando con respuestas heur√≠sticas - Gemini no disponible"
        else:
            status = "unhealthy"
            message = "Datos meteorol√≥gicos no disponibles"
        
        return {
            "status": status,
            "service": "Hybrid Chat Service",
            "message": message,
            "timestamp": datetime.now().isoformat(),
            "capabilities": {
                "heuristic_responses": data_available,
                "gemini_ai": gemini_available,
                "data_records": len(chatbot_service.df) if data_available else 0,
                "stations_count": chatbot_service.df['station_id'].nunique() if data_available else 0
            }
        }
            
    except Exception as e:
        logger.error(f"Error en health check de chat h√≠brido: {e}")
        return {
            "status": "unhealthy",
            "service": "Hybrid Chat Service",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

@router.get("/info")
async def chat_info():
    """
    Informaci√≥n completa sobre el chatbot Nubi ‚òÅÔ∏è - Sistema H√≠brido
    """
    return {
        "name": "Nubi ‚òÅÔ∏è",
        "description": "Asistente ambiental h√≠brido con IA para datos meteorol√≥gicos",
        "version": "2.0.0",
        "system_type": "Hybrid (Heuristic + AI)",
        "capabilities": [
            "üöÄ Respuestas heur√≠sticas instant√°neas",
            "ü§ñ An√°lisis inteligente con Gemini IA", 
            "üìä Consultar estado actual de estaciones",
            "üìç Listar estaciones disponibles",
            "üìö Explicar conceptos meteorol√≥gicos",
            "üå¨Ô∏è Interpretar calidad del aire",
            "üìà An√°lisis comparativo de datos",
            "üîç Preguntas abiertas sobre clima",
            "üõ°Ô∏è Validaci√≥n de scope autom√°tica"
        ],
        "commands": {
            "a": "Ver estaciones disponibles",
            "b": "Modo educativo - explicar conceptos",
            "hola": "Saludo inicial con opciones",
            "[nombre_estacion]": "Estado actual de una estaci√≥n",
            "¬øqu√© es [variable]?": "Explicaci√≥n de conceptos"
        },
        "variables_supported": [
            "temperatura", "humedad", "presi√≥n", 
            "PM1", "PM2.5", "PM10", "ICA", 
            "precipitaci√≥n", "viento_vel", "viento_dir"
        ],
        "endpoints": {
            "chat": "/chatbot/message - Chat conversacional",
            "data": "/chatbot/data - Datos estructurados completos",
            "query": "/chatbot/query - Consultas filtradas",
            "health": "/chatbot/health - Estado del servicio"
        }
    }

@router.post("/explain", response_model=ChatResponse)
async def explain_data_with_gemini(
    message: ChatMessage,
    chatbot_service: ChatbotService = Depends(get_chatbot_service)
):
    """
    ü§ñ Endpoint espec√≠fico para explicaciones con Gemini IA
    
    Este endpoint SIEMPRE usa Gemini IA, sin pasar por el sistema heur√≠stico.
    Dise√±ado espec√≠ficamente para el bot√≥n "Expl√≠came" que genera preguntas
    contextuales robustas sobre datos meteorol√≥gicos.
    
    Caracter√≠sticas:
    - Fuerza el uso de Gemini IA (no heur√≠stico)
    - Optimizado para an√°lisis de datos complejos
    - Respuestas detalladas y t√©cnicas
    - Contexto meteorol√≥gico especializado
    """
    try:
        logger.info(f"ü§ñ Procesando explicaci√≥n FORZADA con Gemini: {message.message[:100]}...")
        
        # Verificar que Gemini est√© disponible
        if not chatbot_service.has_gemini:
            logger.error("‚ùå Gemini no est√° disponible para explicaciones")
            raise HTTPException(
                status_code=503, 
                detail="El servicio de IA (Gemini) no est√° disponible actualmente"
            )
        
        # FORZAR el uso de Gemini directamente, sin heur√≠sticas
        response_text = await chatbot_service.responder_con_gemini(message.message)
        
        if not response_text or response_text.strip() == "":
            logger.warning("‚ö†Ô∏è Gemini devolvi√≥ respuesta vac√≠a")
            response_text = "Lo siento, no pude generar una explicaci√≥n detallada en este momento. Por favor, intenta de nuevo."
        
        timestamp = datetime.now().isoformat()
        
        logger.info("‚úÖ Explicaci√≥n con Gemini completada exitosamente")
        
        return ChatResponse(
            response=response_text,
            timestamp=timestamp,
            status="success"
        )
        
    except HTTPException:
        # Re-lanzar HTTPExceptions tal como est√°n
        raise
    except Exception as e:
        logger.error(f"‚ùå Error procesando explicaci√≥n con Gemini: {e}")
        raise HTTPException(
            status_code=500, 
            detail=f"Error interno procesando la explicaci√≥n: {str(e)}"
        )
